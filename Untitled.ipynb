{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WomenTech Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Event and connection\n",
    "url = \"https://app.hopin.to/events/womentech-global-conference-2020/reception\"\n",
    "\n",
    "chrome_options = Options()  \n",
    "driver = webdriver.Chrome(executable_path=os.path.abspath(\"chromedriver\"), options=chrome_options) \n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Create BeautifulSoup object\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "# Build presentation titles content list\n",
    "content_list = []\n",
    "schedule = soup.find_all(\"div\", class_=\"text -semi-bold mt-8\")\n",
    "for item in schedule:\n",
    "    content = item.text\n",
    "    content_list.append(content)\n",
    "    \n",
    "# Build presenter titles list\n",
    "titles_list = []\n",
    "titles = soup.find_all(\"p\", class_=\"text -light mt-4\")    \n",
    "for element in titles:\n",
    "    role = element.text\n",
    "    titles_list.append(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete company sessions and expos\n",
    "for item in list(content_list):\n",
    "    if \"Session\" in item:\n",
    "        content_list.remove(item)\n",
    "    elif \"Expo\" in item:\n",
    "        content_list.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 298 panels during the conference excluding career and expo panels.\n",
      "There were 301 presenters at the conference.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There were {len(content_list)} panels during the conference excluding career and expo panels.\")\n",
    "print(f\"There were {len(titles_list)} presenters at the conference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 34), ('a', 28), ('to', 22), ('Tech', 18), ('Power', 11), ('Data', 9), ('Technology', 9), ('new', 9), ('Career', 8), ('COVID-19', 8), ('Building', 8), ('Women', 8), ('Learning', 8), ('your', 8), ('AI', 7), ('Business', 7), ('Social', 6), ('Science', 6), ('Culture', 6), ('Future', 6), ('Leadership', 6), ('build', 6), ('tech', 6), ('journey', 5), ('Intelligence', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Find most frequent words in presentation titles\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, punkt\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Get rid of stopwords\n",
    "drop_chars = [\"a\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"you're\", \"you've\", \"you'll\", \"you'd\", \n",
    "              \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"she's\", \"her\", \"hers\", \n",
    "              \"herself\", \"it\", \"it's\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n",
    "              \"who\", \"whom\", \"this\", \"that\", \"that'll\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \n",
    "              \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \n",
    "              \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n",
    "              \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \n",
    "              \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \n",
    "              \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \n",
    "              \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"don't\", \"should\", \"should've\", \n",
    "              \"now\", \"d\", \"ll\", \"m\", \"o\", \"re\", \"ve\", \"y\", \"ain\", \"aren\", \"aren't\", \"couldn\", \"couldn't\", \"didn\", \"didn't\", \n",
    "              \"doesn\", \"doesn't\", \"hadn\", \"hadn't\", \"hasn\", \"hasn't\", \"haven\", \"haven't\", \"isn\", \"isn't\", \"ma\", \"mightn\", \n",
    "              \"mightn't\", \"mustn\", \"mustn't\", \"needn\", \"needn't\", \"shan\", \"shan't\", \"shouldn\", \"shouldn't\", \"wasn\", \"wasn't\", \n",
    "              \"weren\", \"weren't\", \"won\", \"won't\", \"the\", \"how\", \"wouldn\", \"wouldn't\", \"-\", \":\", \"&\", \",\", \"!\", \"'('\", \"(')'\",\n",
    "              \"/\", \"|\", \"@\"]\n",
    "\n",
    "content_string = ' '.join(content_list)\n",
    "content_split = content_string.split()\n",
    "\n",
    "for word in content_split:\n",
    "    if word.casefold() in drop_chars:\n",
    "        content_split.remove(word)\n",
    "\n",
    "counter_content = Counter(content_split)\n",
    "most_freq_content = counter_content.most_common(25)\n",
    "print(most_freq_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Words in Presenter Titles and Their Counts\n",
      "-------------------------------------\n",
      "[('CEO', 36), ('Founder', 34), ('Software', 33), ('Engineer', 29), ('Senior', 27), ('Director', 24), ('Data', 18), ('Manager', 16), ('Consultant', 16), ('Developer', 14)]\n"
     ]
    }
   ],
   "source": [
    "# Find most frequent titles of presenters\n",
    "titles = []\n",
    "\n",
    "for item in titles_list:\n",
    "    titles.append(item.strip())\n",
    "\n",
    "title_string = ' '.join(titles)\n",
    "title_split = title_string.split()\n",
    "\n",
    "for word in title_split:\n",
    "    if word.casefold() in drop_chars:\n",
    "        title_split.remove(word)\n",
    "\n",
    "counter_titles = Counter(title_split)\n",
    "most_freq_titles = counter_titles.most_common(10)\n",
    "print(\"Most Common Words in Presenter Titles and Their Counts\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "print(most_freq_titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
